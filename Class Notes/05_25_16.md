# COEN 122 Computer Architecture 05_25_16

## Size for Cache

    - DON'T INCLUDE FOR THE INDEX

## Pipeline CPI

    - Best case: 1

## Cache -- Direct Mapped -- Summary

    - Each block in main mem. -> only one fixed location in cache
        - many -> one mapping
        - replacing: replace the block occupying the location
        - cache index = lower-order bits of memory address, excluding byte and block offset
    - Advantages
        - Speed
    - Disadvantages
        - high miss rate
        - not very flexible

## Hits vs Misses

    - Read hits - what we want
    - Read misses
      - stall the cpu, fot=etch block ffrom memory, deliver to cache, restart
    - Write hits: 2 write policies
      - write-trhough: update data in cache and memory right away
        - write buffer: a queue hodling data to be written to menory
      - write-back: update data in cache only (update memory later)
    - Write misses:
      - read the entire block into the cache, then write the word
    - need a dirty bit flag
      - {d | v | tag | data}
      - in write back policy
      - dirty bit = 1 if block is updated
      - dirty bit = 0 otherwise
        - either 0 or 1

## How to handle cache miss

    - basic idea: stall CPU (not interrupt) and do the following
      - send the address of the miss item into memory
      - instruct memory to perform a read and wait for memory to complete access
      - write cache entry (data portion, tag, valid flag)
      - restart
      - ~40 cycles to handle a miss
    - miss penalty: setup time + block size

## Performance

    - Simplified model:
      - execution time = (execution cycles + stall cycles) * cycle time
      - stall cycles = #misses * miss penalty
      - #misses = #I cache misses + #D cache misses
      - miss penalty =
    - Separate caches for instructino and data
      - Instruction and data show different localities
      - No write operation for instruction cache
    - Two ways of improving performance
      - deacreasing the miss ratio
      - decreasing the miss penalty
    - optimal block size is at minimum of # stall cycles

## Cache Misses: 3 C's

    - Compulsory miss (cold start misses)
      - a cache miss caused by the 1st accesss to a block that has never been in the cache
    - capacity miss:
      - a cache miss that occurs because fo the cache size
      - working data is larger than cache size
      - need bigger cache
    - Conflict miss (collision miss)
      - a cache miss that occurs when multiple blocks compete for the same set while other sets
      - are available

## Cache Performance - Example

    - Assume gcc inst cache miss 2%
      - data cache miss 4%
      - cpi without memory stalls: 2
      - miss penalty for all misses: 100 cycles
    - CPU time with stalls / CPU time with perfect cache

|     | loads | store | R-type  | branch  | jumps |
| gcc | 24%   | 12%   | 44%     | 19%     | 2%    |

    - Q1 how much faster a machine with a perfect cace (no misses)
      - I: #misses = 2% * n
        - # penalty cycles = 2% * n * 100 = 2n
      - D: #misses = (24% + 12 %) * n * 4%
        - (24% + 12 %) * n = d cache access
        - #penalty cycles = 36% * n * 4% + 100 = 36% * 4n
          - =1.44n
      - CPU time with stalls / cpu time with perfect cache
        - (2n + 2n + 1.44n) / (2n)
          - = 5.44 / 2
    - Q2 Average penalty cycles per instruction
      - inst miss cycles:
      - data miss cycles:

## Average Memory Access Time

    - HIt time is also important for performance
    - Average memory access time (AMAT)
      - AMAT = Hit time + miss rate * miss penalty
      - AMAT = #time on memory acceses / #memory accesses
    - Ex
      - CPU with 1ns clock time, hit time = 1 cycle, miss penalty - 20 cycles, I-cache miss rate = 5%
      - AMAT = 2 cycles per instruction
      - (I-cache)
      - 1 + 5% * 20 = 1 + 1 = 2 cycles
    - Miss penalty: time(transfer the block to upper level)

END
